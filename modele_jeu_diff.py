from random import randint
import gym
import numpy as np
from gym import spaces
from game import CoinceGame
from utils import Card, Rank, Suit

class CoincheEnv(gym.Env):
    def __init__(self):
        super(CoincheEnv, self).__init__()
        self.game = CoinceGame()

        self.suit = ["SPADES", "HEARTS", "DIAMONDS", "CLUBS", "No_ASSET","Full_ASSET"]
        self.rank = ["7", "8", "9", "10", "J", "Q", "K", "A"]
        self.current_player = 0
        # D√©finition des espaces d'observation et d'action
        self.observation_space = spaces.Box(low=0, high=1, shape=(48,), dtype=np.float32)  # Repr√©sentation des cartes en main
        self.action_space = spaces.Discrete(8)  # Nombre total d'actions possibles (annonces, jeux de cartes, etc.)
        self.history = []

        self.reset()

    def reset(self):
        """R√©initialise le jeu et retourne l'√©tat initial."""
        self.game = CoinceGame()
        self.game.shuffle_deck()
        self.game.deal_card(self.game.current_player, [3, 2, 3])
        self.set_bid()
        self.current_player = self.game.current_player
        self.game.table.set_current_player(self.current_player)
        self.state = self.get_observation()
        return self.state

    def set_bid(self):
        player = randint(0, 3)
        couleur = randint(0, 5)
        self.game.table.announce((80,self.suit[couleur]), player)

    def get_observation(self):
        """Retourne une observation compl√®te en encodant mieux la main du joueur."""
        
        observation = np.zeros(48)  # 8 (main) + 1 (atout) + 1 (contrat) + 1 (coinche) + 1 (tour) + 4 (cartes pos√©es) + 28 (plis pr√©c√©dents)

        current_player = self.current_player

        # 1Ô∏è‚É£ Encodage de la main (8 entr√©es, index des cartes ou -1 si absent)
        cards_in_hand = self.game.players[current_player].get_card()
        for i in range(8):
            if i < len(cards_in_hand):
                observation[i] = self.card_to_index(cards_in_hand[i]) / 52.0  # Normalis√©
            else:
                observation[i] = -1  # Placeholder pour cartes manquantes

        # 2Ô∏è‚É£ Atout (1 entr√©e, normalis√©)
        observation[8] = self.suit.index(self.game.table.get_current_asset())

        # 3Ô∏è‚É£ Contrat (1 entr√©e, normalis√©)
        observation[9] = (self.game.table.get_current_bid().get_points() - 80) 

        # 4Ô∏è‚É£ Coinche (1 entr√©e)
        observation[10] = self.game.table.get_current_bid().get_coef()

        # 5Ô∏è‚É£ Tour actuel (1 entr√©e, normalis√©)
        observation[11] = (8 - len(self.game.players[0].get_card())) / 8.0  

        # 6Ô∏è‚É£ Cartes pos√©es (4 entr√©es, index normalis√©s ou -1 si vide)
        for i, card in enumerate(self.game.table.get_card()):
            observation[12 + i] = self.card_to_index(card) / 52.0 
        for i in range(len(self.game.table.get_card()), 4):
            observation[12 + i] = -1  # Cartes non jou√©es

        # 7Ô∏è‚É£ Plis pr√©c√©dents (32 entr√©es max, 7 derniers plis)
        pli_offset = 16
        last_plis = self.game.table.get_all_cards()  # On prend les 7 derniers plis max
        for i, card in enumerate(last_plis):
            index = pli_offset + i
            observation[index] = self.card_to_index(card) / 52.0  
        for i in range(len(last_plis), 32):  # Remplir les espaces vides
            observation[pli_offset + i] = -1

        return observation



    def card_to_index(self, card):
        """Convertit une carte en un index unique dans l'observation."""
        suits = {"HEARTS": 0, "DIAMONDS": 1, "CLUBS": 2, "SPADES": 3}
        ranks = {"7": 0, "8": 1, "9": 2, "10": 3, "J": 4, "Q": 5, "K": 6, "A": 7}
        return suits[card.suit.name] * 8 + ranks[card.rank.value]

    def step(self, action):

        """Ex√©cute une action et met √† jour l'√©tat du jeu."""
        
        legal_cards = self.game.get_legal_cards(self.game.players[self.current_player])
        
        # V√©rifier que l'action correspond bien √† une carte l√©gale
        if action >= len(self.game.players[self.current_player].get_card()):
            reward = -10  # P√©nalit√© pour action hors limite
            return self.get_observation(), reward, False, {}
        
        chosen_card = self.game.players[self.current_player].get_card()[action]

        if chosen_card not in legal_cards:
            reward = -10  # P√©nalit√© pour action ill√©gale
            return self.get_observation(), reward, False, {}

        self.history.append((self.get_observation(), action, chosen_card))
            
        # Jouer la carte si valide
        self.game.players[self.current_player].play_card(chosen_card)
        self.game.table.play(chosen_card, self.current_player)
        self.current_player = (self.current_player + 1) % 4

        reward = 0  # üõë Pas de r√©compense imm√©diate tant que le pli n'est pas fini

        # 1Ô∏è‚É£ Si le pli est termin√© (4 cartes jou√©es), attribuer la r√©compense diff√©r√©e
        if len(self.game.table.get_card()) == 4:
            self.game.players[self.game.table.get_player_win()].get_team().add_round_score(self.game.table.get_points())
            winning_player = self.game.table.get_player_win()
            winning_team = winning_player % 2
            my_team = self.current_player % 2

            # üéØ **R√©compenses dynamiques bas√©es sur les cartes**
            rewards = []

            for state, action, card in self.history:
                if self.game.players[self.current_player].get_team() == winning_team:
                    card_strength = self.evaluate_card(card)  # Score de la carte
                    reward = 0.5 + 0.5 * card_strength  # Plus forte = plus r√©compens√©e
                else:
                    reward = -0.5  # Malus si on perd le pli
                rewards.append((state, action, reward))

            self.current_player = winning_player  # Le gagnant commence le prochain pli
            self.game.table.plis_end()

            # üèÜ Donner les r√©compenses calcul√©es
            final_state, final_action, final_reward = rewards.pop(0)
            self.history.clear()
            return final_state, final_reward, False, {}
        
        if self.game.round_finish():
            self.game.players[self.game.table.get_current_player()].get_team().add_round_score(10)
            _,_ = self.game.round_end()
            self.game.table.empty_cards()
            self.game.deck.cut()
            self.game.deal_card(self.current_player, [3, 2, 3])
            self.set_bid()
            self.current_player = self.game.current_player
            self.game.table.set_current_player(self.current_player)
    
        reward = self.compute_reward(self.current_player)
        done = self.game.game_finish()
        
        return self.get_observation(), reward, done, {}

    def compute_reward(self,player):
        """Calcule une r√©compense pour l'IA en fonction de l'√©tat du jeu."""
        team_score = self.game.players[player].get_team().get_round_score()  # Score de l'√©quipe de l'IA
        opponent_score = self.game.teams[1].get_round_score()  # Score de l'adversaire
        return team_score - opponent_score

    def render(self, mode="human"):
        """Affichage pour d√©boguer."""
        # print(f"√âtat du jeu : {self.get_observation()}")


if __name__ == "__main__":
    env = CoincheEnv()
    obs = env.reset()
    done = False

    while not done:
        action = env.action_space.sample()  # Action al√©atoire pour tester
        obs, reward, done, _ = env.step(action)
        env.render()
